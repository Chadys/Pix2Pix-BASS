{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "music_pix2pix.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLi8vQOlAl7i",
        "colab_type": "text"
      },
      "source": [
        "Refs : \n",
        "\n",
        "https://www.tensorflow.org/alpha/tutorials/generative/pix2pix\n",
        "\n",
        "https://www.tensorflow.org/alpha/tutorials/distribute/training_loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5egXuDM3m7j",
        "colab_type": "code",
        "outputId": "84362d98-fc81-41b5-f290-382179989731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "#!pip install -q tensorflow-gpu==2.0.0-alpha0\n",
        "!pip install -q tf-nightly-gpu-2.0-preview\n",
        "!pip install -q musdb museval\n",
        "!apt install ffmpeg\n",
        "\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.ops import nn\n",
        "from tensorflow.python.framework import tensor_shape\n",
        "from tensorflow.python.keras.engine.input_spec import InputSpec\n",
        "from tensorflow.python.ops import array_ops\n",
        "from tensorflow.python.keras.utils import conv_utils\n",
        "from tensorflow.python.eager import context\n",
        "import musdb\n",
        "import museval\n",
        "import numpy as np\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 349.2MB 63kB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 27.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 430kB 56.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 32.1MB/s \n",
            "\u001b[?25h  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: thinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.1 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 512kB 8.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 31.4MB/s \n",
            "\u001b[?25h  Building wheel for simplejson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.6-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 6 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4X8yoKD0kp_",
        "colab_type": "code",
        "outputId": "e17f0448-1769-4151-81f5-e290a6efcf40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from tensorflow.python.ops import control_flow_util\n",
        "control_flow_util.ENABLE_CONTROL_FLOW_V2 = True\n",
        "from packaging import version\n",
        "\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
        "    \"This notebook requires TensorFlow 2.0 or above.\"\n",
        "\n",
        "print(\"Executing eagerly : {}\".format(tf.executing_eagerly()))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version:  2.0.0-dev20190527\n",
            "Executing eagerly : True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4hgJseWeeXE",
        "colab_type": "code",
        "outputId": "9097d5a0-c145-43a2-83af-55700451d81f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!mkdir -p /content/gdrive/My\\ Drive/musdb18\n",
        "!cp -a /content/gdrive/My\\ Drive/musdb18 /content/musdb18"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs_MAEHl4N_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q -n /content/gdrive/My\\ Drive/musdb18.zip -d sample_data/musdb18\n",
        "\n",
        "mus = musdb.DB(root_dir='sample_data/musdb18')\n",
        "tracks = mus.load_mus_tracks(subsets=['train'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4CNyvaWG20x",
        "colab_type": "code",
        "outputId": "86444eb5-cc06-4a4d-8fa7-fd4c5c6d3b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# waiting for Cloud TPU 1.14 release https://github.com/tensorflow/tensorflow/issues/24412\n",
        "#resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "#tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "#strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of devices: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aeb98673-9028-4bed-d92f-f092ef58dd43",
        "id": "TOkBFhS_TtYC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "min_track_length = 569344 # min(tracks, key=lambda t: t.audio.shape[0]).audio.shape[0]\n",
        "max_track_length = 27711488  # max(tracks, key=lambda t: t.audio.shape[0]).audio.shape[0]\n",
        "print(\"max track length = {}\".format(min_track_length))\n",
        "print(\"max track length = {}\".format(max_track_length))\n",
        "print(\"min value = {}\".format(-1.))  # min(t.audio.min() for t in tracks)))\n",
        "print(\"max value = {}\".format(1.))  # max(t.audio.max() for t in tracks)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max track length = 569344\n",
            "max track length = 27711488\n",
            "min value = -1.0\n",
            "max value = 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v871bsHHUQAR",
        "colab_type": "code",
        "outputId": "9975ffd7-5a8b-4fad-ceba-18ce8a7ff007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# ensure the size is a power of two, and no longer than the shortest track\n",
        "INPUT_SIZE = min(32768, 2**int(np.log2(min_track_length)))\n",
        "BATCH_SIZE = 16 * strategy.num_replicas_in_sync  # use 128 on TPU\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "OUTPUT_CHANNELS = tracks[0].audio.shape[1]\n",
        "LAMBDA = 100\n",
        "EPOCHS = 500\n",
        "SAVE_FREQ = 5\n",
        "LOG_FREQ = 10\n",
        "VALIDATION_SPLIT = 0.2\n",
        "n_validation = max(int(len(tracks) * VALIDATION_SPLIT), BATCH_SIZE)  # n_validation needs to be at least BATCH_SIZE or no validation will take place\n",
        "n_train = len(tracks) - n_validation\n",
        "validation_steps_per_epoch = n_validation // BATCH_SIZE\n",
        "train_steps_per_epoch = n_train // BATCH_SIZE\n",
        "\n",
        "print(\"INPUT_SIZE : {}\".format(INPUT_SIZE))\n",
        "print(\"BATCH_SIZE : {}\".format(BATCH_SIZE))\n",
        "print(\"OUTPUT_CHANNELS : {}\".format(OUTPUT_CHANNELS))\n",
        "print(\"Validation set size : {}\".format(n_validation))\n",
        "print(\"Train set size : {}\".format(n_train))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT_SIZE : 32768\n",
            "BATCH_SIZE : 16\n",
            "OUTPUT_CHANNELS : 2\n",
            "Validation set size : 20\n",
            "Train set size : 80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btemEeoF4Pff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_tracks = tracks[:n_validation]\n",
        "train_tracks = tracks[n_validation:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nNlPWxM8Imh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _preprocess_conv1d_input(x, data_format):\n",
        "  \"\"\"Transpose and cast the input before the conv1d.\n",
        "  Arguments:\n",
        "      x: input tensor.\n",
        "      data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n",
        "  Returns:\n",
        "      A tensor.\n",
        "  \"\"\"\n",
        "  tf_data_format = 'NWC'  # to pass TF Conv2dNative operations\n",
        "  if data_format == 'channels_first':\n",
        "    if not _has_nchw_support():\n",
        "      x = array_ops.transpose(x, (0, 2, 1))  # NCW -> NWC\n",
        "    else:\n",
        "      tf_data_format = 'NCW'\n",
        "  return x, tf_data_format\n",
        "\n",
        "def _preprocess_padding(padding):\n",
        "  \"\"\"Convert keras' padding to TensorFlow's padding.\n",
        "  Arguments:\n",
        "      padding: string, one of 'same' , 'valid'\n",
        "  Returns:\n",
        "      a string, one of 'SAME', 'VALID'.\n",
        "  Raises:\n",
        "      ValueError: if invalid `padding'`\n",
        "  \"\"\"\n",
        "  if padding == 'same':\n",
        "    padding = 'SAME'\n",
        "  elif padding == 'valid':\n",
        "    padding = 'VALID'\n",
        "  else:\n",
        "    raise ValueError('Invalid padding: ' + str(padding))\n",
        "  return padding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2J-Z255D0kd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ref : tf.keras.backend.conv2d_transpose\n",
        "# https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/keras/backend.py\n",
        "\n",
        "def conv1d_transpose(x,\n",
        "                     kernel,\n",
        "                     output_shape,\n",
        "                     strides=(1,),\n",
        "                     padding='valid',\n",
        "                     data_format=None):\n",
        "  \"\"\"1D deconvolution (i.e.\n",
        "  transposed convolution).\n",
        "  Arguments:\n",
        "      x: Tensor or variable.\n",
        "      kernel: kernel tensor.\n",
        "      output_shape: 1D int tensor for the output shape.\n",
        "      strides: strides integer.\n",
        "      padding: string, `\"same\"` or `\"valid\"`.\n",
        "      data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n",
        "          Whether to use Theano or TensorFlow/CNTK data format\n",
        "          for inputs/kernels/outputs.\n",
        "      dilation_rate: integer.\n",
        "  Returns:\n",
        "      A tensor, result of transposed 1D convolution.\n",
        "  Raises:\n",
        "      ValueError: if `data_format` is neither `channels_last` or\n",
        "      `channels_first`.\n",
        "  \"\"\"\n",
        "  if data_format is None:\n",
        "    data_format = image_data_format()\n",
        "  if data_format not in {'channels_first', 'channels_last'}:\n",
        "    raise ValueError('Unknown data_format: ' + str(data_format))\n",
        "  if isinstance(output_shape, (tuple, list)):\n",
        "    output_shape = array_ops.stack(output_shape)\n",
        "\n",
        "  x, tf_data_format = _preprocess_conv1d_input(x, data_format)\n",
        "\n",
        "  if data_format == 'channels_first' and tf_data_format == 'NWC':\n",
        "    output_shape = (output_shape[0], output_shape[2], output_shape[1])\n",
        "  if output_shape[0] is None:\n",
        "    output_shape = (array_ops.shape(x)[0],) + tuple(output_shape[1:])\n",
        "    output_shape = array_ops.stack(list(output_shape))\n",
        "\n",
        "  padding = _preprocess_padding(padding)\n",
        "  if tf_data_format == 'NWC':\n",
        "    strides = (1,) + strides + (1,)\n",
        "  else:\n",
        "    strides = (1, 1) + strides\n",
        "  x = nn.conv1d_transpose(x, \n",
        "                          kernel, \n",
        "                          output_shape, \n",
        "                          list(strides),\n",
        "                          padding=padding,\n",
        "                          data_format=tf_data_format)\n",
        "  if data_format == 'channels_first' and tf_data_format == 'NWC':\n",
        "    x = array_ops.transpose(x, (0, 2, 1))  # NWC -> NCW\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7IN9J-lD13V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ref : tf.keras.layers.Conv2DTranspose\n",
        "# https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/convolutional.py\n",
        "\n",
        "class Conv1DTranspose(tf.keras.layers.Conv1D):\n",
        "  \"\"\"Transposed convolution layer (sometimes called Deconvolution).\n",
        "  The need for transposed convolutions generally arises\n",
        "  from the desire to use a transformation going in the opposite direction\n",
        "  of a normal convolution, i.e., from something that has the shape of the\n",
        "  output of some convolution to something that has the shape of its input\n",
        "  while maintaining a connectivity pattern that is compatible with\n",
        "  said convolution.\n",
        "  When using this layer as the first layer in a model,\n",
        "  provide the keyword argument `input_shape`\n",
        "  (tuple of integers, does not include the sample axis),\n",
        "  e.g. `input_shape=(128, 2)` for 128 units long stereo sound\n",
        "  in `data_format=\"channels_last\"`.\n",
        "  Arguments:\n",
        "    filters: Integer, the dimensionality of the output space\n",
        "      (i.e. the number of output filters in the convolution).\n",
        "    kernel_size: An integer specifying the width of the 1D\n",
        "      convolution window.\n",
        "    strides: An integer specifying the strides of the \n",
        "      convolution along the width.\n",
        "      Specifying any stride value != 1 is incompatible with specifying\n",
        "      any `dilation_rate` value != 1.\n",
        "    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
        "    output_padding: An integer specifying the amount of padding along\n",
        "      the width of the output tensor.\n",
        "      The amount of output padding along a given dimension must be\n",
        "      lower than the stride along that same dimension.\n",
        "      If set to `None` (default), the output shape is inferred.\n",
        "    data_format: A string,\n",
        "      one of `channels_last` (default) or `channels_first`.\n",
        "      The ordering of the dimensions in the inputs.\n",
        "      `channels_last` corresponds to inputs with shape\n",
        "      `(batch, width, channels)` while `channels_first`\n",
        "      corresponds to inputs with shape\n",
        "      `(batch, channels, width)`.\n",
        "      It defaults to the `image_data_format` value found in your\n",
        "      Keras config file at `~/.keras/keras.json`.\n",
        "      If you never set it, then it will be \"channels_last\".\n",
        "    dilation_rate: an integer specifying\n",
        "      the dilation rate to use for dilated convolution.\n",
        "      Currently, specifying any `dilation_rate` value != 1 is\n",
        "      incompatible with specifying any stride value != 1.\n",
        "    activation: Activation function to use.\n",
        "      If you don't specify anything, no activation is applied\n",
        "      (ie. \"linear\" activation: `a(x) = x`).\n",
        "    use_bias: Boolean, whether the layer uses a bias vector.\n",
        "    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
        "    bias_initializer: Initializer for the bias vector.\n",
        "    kernel_regularizer: Regularizer function applied to\n",
        "      the `kernel` weights matrix.\n",
        "    bias_regularizer: Regularizer function applied to the bias vector.\n",
        "    activity_regularizer: Regularizer function applied to\n",
        "      the output of the layer (its \"activation\")..\n",
        "    kernel_constraint: Constraint function applied to the kernel matrix.\n",
        "    bias_constraint: Constraint function applied to the bias vector.\n",
        "  Input shape:\n",
        "    3D tensor with shape:\n",
        "    `(batch, channels, cols)` if data_format='channels_first'\n",
        "    or 3D tensor with shape:\n",
        "    `(batch, cols, channels)` if data_format='channels_last'.\n",
        "  Output shape:\n",
        "    3D tensor with shape:\n",
        "    `(batch, filters, new_cols)` if data_format='channels_first'\n",
        "    or 3D tensor with shape:\n",
        "    `(batch, new_cols, filters)` if data_format='channels_last'.\n",
        "    `cols` value might have changed due to padding.\n",
        "  References:\n",
        "    - [A guide to convolution arithmetic for deep\n",
        "      learning](https://arxiv.org/abs/1603.07285v1)\n",
        "    - [Deconvolutional\n",
        "      Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               filters,\n",
        "               kernel_size,\n",
        "               strides=1,\n",
        "               padding='valid',\n",
        "               output_padding=None,\n",
        "               data_format=None,\n",
        "               dilation_rate=(1,),\n",
        "               activation=None,\n",
        "               use_bias=True,\n",
        "               kernel_initializer='glorot_uniform',\n",
        "               bias_initializer='zeros',\n",
        "               kernel_regularizer=None,\n",
        "               bias_regularizer=None,\n",
        "               activity_regularizer=None,\n",
        "               kernel_constraint=None,\n",
        "               bias_constraint=None,\n",
        "               **kwargs):\n",
        "    super().__init__(\n",
        "        filters=filters,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        padding=padding,\n",
        "        data_format=data_format,\n",
        "        dilation_rate=dilation_rate,\n",
        "        activation=tf.keras.activations.get(activation),\n",
        "        use_bias=use_bias,\n",
        "        kernel_initializer=tf.keras.initializers.get(kernel_initializer),\n",
        "        bias_initializer=tf.keras.initializers.get(bias_initializer),\n",
        "        kernel_regularizer=tf.keras.regularizers.get(kernel_regularizer),\n",
        "        bias_regularizer=tf.keras.regularizers.get(bias_regularizer),\n",
        "        activity_regularizer=tf.keras.regularizers.get(activity_regularizer),\n",
        "        kernel_constraint=tf.keras.constraints.get(kernel_constraint),\n",
        "        bias_constraint=tf.keras.constraints.get(bias_constraint),\n",
        "        **kwargs)\n",
        "\n",
        "    self.output_padding = output_padding\n",
        "    if self.output_padding is not None:\n",
        "      self.output_padding = conv_utils.normalize_tuple(\n",
        "          self.output_padding, 1, 'output_padding')\n",
        "      for stride, out_pad in zip(self.strides, self.output_padding):\n",
        "        if out_pad >= stride:\n",
        "          raise ValueError('Stride ' + str(self.strides) + ' must be '\n",
        "                           'greater than output padding ' +\n",
        "                           str(self.output_padding))\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    input_shape = tensor_shape.TensorShape(input_shape)\n",
        "    if len(input_shape) != 3:\n",
        "      raise ValueError('Inputs should have rank 3. Received input shape: ' +\n",
        "                       str(input_shape))\n",
        "    if self.data_format == 'channels_first':\n",
        "      channel_axis = 1\n",
        "    else:\n",
        "      channel_axis = -1\n",
        "    if input_shape.dims[channel_axis].value is None:\n",
        "      raise ValueError('The channel dimension of the inputs '\n",
        "                       'should be defined. Found None: ' + str(input_shape))\n",
        "    input_dim = int(input_shape[channel_axis])\n",
        "    self.input_spec = InputSpec(ndim=3, axes={channel_axis: input_dim})\n",
        "    kernel_shape = self.kernel_size + (self.filters, input_dim)\n",
        "\n",
        "    self.kernel = self.add_weight(\n",
        "        name='kernel',\n",
        "        shape=kernel_shape,\n",
        "        initializer=self.kernel_initializer,\n",
        "        regularizer=self.kernel_regularizer,\n",
        "        constraint=self.kernel_constraint,\n",
        "        trainable=True,\n",
        "        dtype=self.dtype)\n",
        "    if self.use_bias:\n",
        "      self.bias = self.add_weight(\n",
        "          name='bias',\n",
        "          shape=(self.filters,),\n",
        "          initializer=self.bias_initializer,\n",
        "          regularizer=self.bias_regularizer,\n",
        "          constraint=self.bias_constraint,\n",
        "          trainable=True,\n",
        "          dtype=self.dtype)\n",
        "    else:\n",
        "      self.bias = None\n",
        "    self.built = True\n",
        "\n",
        "  def call(self, inputs):\n",
        "    inputs_shape = array_ops.shape(inputs)\n",
        "    batch_size = inputs_shape[0]\n",
        "    if self.data_format == 'channels_first':\n",
        "      w_axis = 2\n",
        "    else:\n",
        "      w_axis = 1\n",
        "\n",
        "    width = inputs_shape[w_axis]\n",
        "    kernel_w = self.kernel_size[0]\n",
        "    stride_w = self.strides[0]\n",
        "\n",
        "    if self.output_padding is None:\n",
        "      out_pad_w = None\n",
        "    else:\n",
        "      out_pad_w = self.output_padding[0]\n",
        "\n",
        "    # Infer the dynamic output shape:\n",
        "    out_width = conv_utils.deconv_output_length(width,\n",
        "                                                kernel_w,\n",
        "                                                padding=self.padding,\n",
        "                                                output_padding=out_pad_w,\n",
        "                                                stride=stride_w)\n",
        "    if self.data_format == 'channels_first':\n",
        "      output_shape = (batch_size, self.filters, out_width)\n",
        "    else:\n",
        "      output_shape = (batch_size, out_width, self.filters)\n",
        "\n",
        "    output_shape_tensor = array_ops.stack(output_shape)\n",
        "    outputs = conv1d_transpose(\n",
        "        inputs,\n",
        "        self.kernel,\n",
        "        output_shape_tensor,\n",
        "        strides=self.strides,\n",
        "        padding=self.padding,\n",
        "        data_format=self.data_format)\n",
        "\n",
        "    if not context.executing_eagerly():\n",
        "      # Infer the static output shape:\n",
        "      out_shape = self.compute_output_shape(inputs.shape)\n",
        "      outputs.set_shape(out_shape)\n",
        "\n",
        "    if self.use_bias:\n",
        "      outputs = nn.bias_add(\n",
        "          outputs,\n",
        "          self.bias,\n",
        "          data_format=conv_utils.convert_data_format(self.data_format, ndim=3))\n",
        "\n",
        "    if self.activation is not None:\n",
        "      return self.activation(outputs)\n",
        "    return outputs\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    input_shape = tensor_shape.TensorShape(input_shape).as_list()\n",
        "    output_shape = list(input_shape)\n",
        "    if self.data_format == 'channels_first':\n",
        "      c_axis, w_axis = 1, 2\n",
        "    else:\n",
        "      c_axis, w_axis = 2, 1\n",
        "\n",
        "    kernel_w = self.kernel_size[0]\n",
        "    stride_w = self.strides[0]\n",
        "\n",
        "    if self.output_padding is None:\n",
        "      out_pad_w = None\n",
        "    else:\n",
        "      out_pad_w = self.output_padding[0]\n",
        "\n",
        "    output_shape[c_axis] = self.filters\n",
        "    output_shape[w_axis] = conv_utils.deconv_output_length(\n",
        "        output_shape[w_axis],\n",
        "        kernel_w,\n",
        "        padding=self.padding,\n",
        "        output_padding=out_pad_w,\n",
        "        stride=stride_w)\n",
        "    return tensor_shape.TensorShape(output_shape)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    config['output_padding'] = self.output_padding\n",
        "    config.pop('dilation_rate')\n",
        "    return config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy27Zqetu7dM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def downsample(filters, size, apply_batchnorm=True):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "      tf.keras.layers.Conv1D(filters, size, strides=2, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False))\n",
        "\n",
        "  if apply_batchnorm:\n",
        "    result.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  result.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPBP6SjzwesR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def upsample(filters, size, apply_dropout=False):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "    Conv1DTranspose(filters, size, strides=2,\n",
        "                    padding='same',\n",
        "                    kernel_initializer=initializer,\n",
        "                    use_bias=False))\n",
        "\n",
        "  result.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  if apply_dropout:\n",
        "      result.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "  result.add(tf.keras.layers.ReLU())\n",
        "\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcygEwXRwquy",
        "colab_type": "code",
        "outputId": "21ad5cbb-22ea-4435-b2eb-c0cb769fca92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "inp = tf.expand_dims(tracks[0].audio, 0)\n",
        "print(inp.shape)\n",
        "down_model = downsample(2, (4,))\n",
        "down_result = down_model(inp)\n",
        "print(down_result.shape)\n",
        "up_model = upsample(2, (4,))\n",
        "up_result = up_model(down_result)\n",
        "print(up_result.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 7552000, 2)\n",
            "(1, 3776000, 2)\n",
            "(1, 7552000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUGeRaK0iT0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Generator():\n",
        "  down_stack = [\n",
        "    downsample(64, 4, apply_batchnorm=False),  # (bs, 65536, 64)\n",
        "    downsample(128, 4),  # (bs, 32768, 128)\n",
        "    downsample(256, 4),  # (bs, 16384, 256)\n",
        "    downsample(512, 4),  # (bs, 8192, 512)\n",
        "    downsample(512, 4),  # (bs, 4096, 512)\n",
        "    downsample(512, 4),  # (bs, 2048, 512)\n",
        "    downsample(512, 4),  # (bs, 1024, 512)\n",
        "    downsample(512, 4),  # (bs, 512, 512)\n",
        "  ]\n",
        "\n",
        "  up_stack = [\n",
        "    upsample(512, 4, apply_dropout=True),  # (bs, 1024, 1024)\n",
        "    upsample(512, 4, apply_dropout=True),  # (bs, 2048, 1024)\n",
        "    upsample(512, 4, apply_dropout=True),  # (bs, 4096, 1024)\n",
        "    upsample(512, 4),  # (bs, 8192, 1024)\n",
        "    upsample(256, 4),  # (bs, 16384, 512)\n",
        "    upsample(128, 4),  # (bs, 32768, 256)\n",
        "    upsample(64, 4),  # (bs, 65536, 128)\n",
        "  ]\n",
        "  \n",
        "  initializer = tf.random_normal_initializer(0.02)\n",
        "  last = Conv1DTranspose(OUTPUT_CHANNELS, 4,\n",
        "                         strides=2,\n",
        "                         padding='same',\n",
        "                         kernel_initializer=initializer,\n",
        "                         activation='tanh')  # (bs, 131072(=INPUT_SIZE), 2)\n",
        "\n",
        "  concat = tf.keras.layers.Concatenate()\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=[None, OUTPUT_CHANNELS])\n",
        "  x = inputs\n",
        "\n",
        "  # Downsampling through the model\n",
        "  skips = []\n",
        "  for down in down_stack:\n",
        "    x = down(x)\n",
        "    skips.append(x)\n",
        "\n",
        "  skips = reversed(skips[:-1])\n",
        "\n",
        "  # Upsampling and establishing the skip connections\n",
        "  for up, skip in zip(up_stack, skips):\n",
        "    x = up(x)\n",
        "    x = concat([x, skip])\n",
        "\n",
        "  x = last(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwlNK90Ri-LT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Discriminator():\n",
        "  initializer = tf.random_normal_initializer(0.02)\n",
        "\n",
        "  inp = tf.keras.layers.Input(shape=[None, OUTPUT_CHANNELS], name='input_image')\n",
        "  tar = tf.keras.layers.Input(shape=[None, OUTPUT_CHANNELS], name='target_image')\n",
        "\n",
        "  x = tf.keras.layers.concatenate([inp, tar])  # (128, 131072(=INPUT_SIZE), 4)\n",
        "\n",
        "  down1 = downsample(64, 4, False)(x)  # (128, 65536, 64)\n",
        "  down2 = downsample(128, 4)(down1)  # (128, 32768, 128)\n",
        "  down3 = downsample(256, 4)(down2)  # (128, 16384, 256)\n",
        "\n",
        "  zero_pad1 = tf.keras.layers.ZeroPadding1D()(down3)  # (128, 16386, 256)\n",
        "  conv = tf.keras.layers.Conv1D(512, 4, strides=1,\n",
        "                                kernel_initializer=initializer,\n",
        "                                use_bias=False)(zero_pad1)  # (128, 16383, 512)\n",
        "\n",
        "  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
        "\n",
        "  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
        "\n",
        "  zero_pad2 = tf.keras.layers.ZeroPadding1D()(leaky_relu)  # (128, 16385, 512)\n",
        "\n",
        "  last = tf.keras.layers.Conv1D(1, 4, strides=1,\n",
        "                                kernel_initializer=initializer)(zero_pad2)  # (128, 16382, 1)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inp, tar], outputs=last)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rFzQ9ssRtmw",
        "colab_type": "code",
        "outputId": "7cd834fd-e8d7-4dbb-e5b1-d0b4ac95f78c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "# MODEL OBJECTS\n",
        "with strategy.scope():\n",
        "  generator = Generator()\n",
        "  discriminator = Discriminator()\n",
        "  generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "  discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0527 16:41:58.270230 140503906137984 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/normalization.py:617: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5frBY-ILf5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM)  # reduction because of parallel strategy\n",
        "  train_gen_loss = tf.keras.metrics.Mean(name='train_gen_loss')\n",
        "  validation_gen_loss = tf.keras.metrics.Mean(name='validation_gen_loss')\n",
        "  train_disc_loss = tf.keras.metrics.Mean(name='train_disc_loss')\n",
        "  validation_disc_loss = tf.keras.metrics.Mean(name='validation_disc_loss')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfdDJmhbRh0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output) * (1. / BATCH_SIZE)\n",
        "\n",
        "  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output) * (1. / BATCH_SIZE)\n",
        "\n",
        "  total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "  return total_disc_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLo22ib8RFq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_loss(disc_generated_output, gen_output, target):\n",
        "  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output) * (1. / BATCH_SIZE)\n",
        "\n",
        "  # mean absolute error\n",
        "  # don't use reduce_mean because of parallel strategy\n",
        "  l1_loss = tf.reduce_sum(tf.abs(target - gen_output)) * (1. / BATCH_SIZE)\n",
        "\n",
        "  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
        "\n",
        "  return total_gen_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0brd2GDQrYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute a batch of INPUT_SIZE samples\n",
        "with strategy.scope():\n",
        "  def get_buffered_data(data, eval_accessor=\"\"):\n",
        "      return tf.cast(\n",
        "          tf.concat(\n",
        "              [\n",
        "                  tf.split(\n",
        "                      (eval(\"t{}\".format(eval_accessor)) if eval_accessor else t).audio[\n",
        "                          : t.audio.shape[0] - t.audio.shape[0] % INPUT_SIZE\n",
        "                      ],\n",
        "                      [INPUT_SIZE] * (t.audio.shape[0] // INPUT_SIZE),\n",
        "                      axis=0,\n",
        "                  )\n",
        "                  for t in data\n",
        "              ],\n",
        "              axis=0,\n",
        "          ),\n",
        "          dtype=tf.float32,\n",
        "      )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8THTbY8us1oe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Generators\n",
        "with strategy.scope():\n",
        "  def dataset_gen(n_data, data):\n",
        "    for i in range(0, n_data, 5):\n",
        "      tracks_sample = data[i:i+5]\n",
        "      sample_dataset = tf.stack((\n",
        "          get_buffered_data(tracks_sample), \n",
        "          get_buffered_data(tracks_sample, \".targets['vocals']\")\n",
        "      ), axis=1)\n",
        "      for sample in sample_dataset:\n",
        "        yield tuple(tf.unstack(sample))\n",
        "        \n",
        "  def train_dataset_gen():\n",
        "    return dataset_gen(n_train, train_tracks)\n",
        "        \n",
        "  def validation_dataset_gen():\n",
        "    return dataset_gen(n_validation, validation_tracks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBmIcwc3wZii",
        "colab_type": "code",
        "outputId": "8781a658-4948-41be-f20a-ef0f48a8d57c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#print(next(train_dataset_gen()))\n",
        "print(tf.TensorShape([INPUT_SIZE, OUTPUT_CHANNELS]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32768, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgFor1AiqXKZ",
        "colab_type": "code",
        "outputId": "732f5fe7-0cb5-40f2-afe9-893a7e4063fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "# DATASET\n",
        "with strategy.scope():\n",
        "  sample_shape = tf.TensorShape([INPUT_SIZE, OUTPUT_CHANNELS])\n",
        "  train_dataset = tf.data.Dataset.from_generator(\n",
        "      train_dataset_gen, \n",
        "      output_types=(tf.float32, tf.float32),\n",
        "      output_shapes=(sample_shape, sample_shape)\n",
        "  )\n",
        "  validation_dataset = tf.data.Dataset.from_generator(\n",
        "      validation_dataset_gen, \n",
        "      output_types=(tf.float32, tf.float32),\n",
        "      output_shapes=(sample_shape, sample_shape)\n",
        "  )\n",
        "  \n",
        "  train_dataset = (train_dataset\n",
        "                  .shuffle(buffer_size=n_train)\n",
        "                  .repeat()\n",
        "                  .batch(BATCH_SIZE, drop_remainder=True)\n",
        "                  .prefetch(AUTOTUNE)\n",
        "                  )\n",
        "                   \n",
        "  validation_dataset = (validation_dataset\n",
        "                       .repeat()\n",
        "                       .batch(BATCH_SIZE, drop_remainder=True)\n",
        "                       .prefetch(AUTOTUNE)\n",
        "                       )\n",
        "  \n",
        "  train_iterator = strategy.make_dataset_iterator(train_dataset)\n",
        "  validation_iterator = strategy.make_dataset_iterator(validation_dataset)\n",
        "                   \n",
        "  print(train_dataset)\n",
        "  print(validation_dataset)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0527 16:42:01.619108 140503906137984 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:499: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<DatasetV1Adapter shapes: ((16, 32768, 2), (16, 32768, 2)), types: (tf.float32, tf.float32)>\n",
            "<DatasetV1Adapter shapes: ((16, 32768, 2), (16, 32768, 2)), types: (tf.float32, tf.float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnUa1whAVlIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_models_are_working():\n",
        "  test_data = validation_iterator.get_next()\n",
        "  validation_iterator.initialize()\n",
        "  print(test_data)\n",
        "  mixture, target = test_data\n",
        "  gen_output = generator(mixture, training=False)\n",
        "  print(gen_output)\n",
        "\n",
        "  disc_real_output = discriminator([mixture, target], training=False)\n",
        "  print(disc_real_output)\n",
        "  disc_generated_output = discriminator([mixture, gen_output], training=False)\n",
        "  print(disc_generated_output)\n",
        "\n",
        "  print(\"gen_loss : {}\".format(generator_loss(disc_generated_output, gen_output, target)))\n",
        "  print(\"disc_loss : {}\".format(discriminator_loss(disc_real_output, disc_generated_output)))\n",
        "\n",
        "# test_models_are_working()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcduefBCR16C",
        "colab_type": "code",
        "outputId": "c3d8f609-dccb-45ba-bf8b-3cf2c6b38ad4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# CHECKPOINTS\n",
        "checkpoint_dir = '/content/musdb18/checkpoints/'\n",
        "\n",
        "with strategy.scope():\n",
        "  checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                   discriminator_optimizer=discriminator_optimizer,\n",
        "                                   generator=generator,\n",
        "                                   discriminator=discriminator)\n",
        "  ckpt_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=5)\n",
        "  \n",
        "  if ckpt_manager.latest_checkpoint:\n",
        "    checkpoint.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Restored from {}\".format(ckpt_manager.latest_checkpoint))\n",
        "  else:\n",
        "    print(\"Initializing from scratch.\")\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Restored from /content/musdb18/checkpoints/ckpt-66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqMmgKBLTJwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAIN STEP\n",
        "with strategy.scope():\n",
        "  def train_step(inputs):\n",
        "    mixture, target = inputs\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      gen_output = generator(mixture, training=True)\n",
        "\n",
        "      disc_real_output = discriminator([mixture, target], training=True)\n",
        "      disc_generated_output = discriminator([mixture, gen_output], training=True)\n",
        "\n",
        "      gen_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "      disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "    generator_gradients = gen_tape.gradient(gen_loss,\n",
        "                                            generator.trainable_variables)\n",
        "    discriminator_gradients = disc_tape.gradient(disc_loss,\n",
        "                                                 discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(generator_gradients,\n",
        "                                            generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
        "                                                discriminator.trainable_variables))\n",
        "    \n",
        "    train_gen_loss.update_state(gen_loss)\n",
        "    train_disc_loss.update_state(disc_loss)\n",
        "    \n",
        "  def validation_step(inputs):\n",
        "    mixture, target = inputs\n",
        "    gen_output = generator(mixture, training=False)\n",
        "    \n",
        "    disc_real_output = discriminator([mixture, target], training=False)\n",
        "    disc_generated_output = discriminator([mixture, gen_output], training=False)\n",
        "    \n",
        "    gen_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "    \n",
        "    validation_gen_loss.update_state(gen_loss)\n",
        "    validation_disc_loss.update_state(disc_loss)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1sAetMPTc_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  # `experimental_run` replicates the provided computation and runs it\n",
        "  # with the distributed input.\n",
        "\n",
        "  @tf.function\n",
        "  def distributed_train():\n",
        "    return strategy.experimental_run(train_step, train_iterator)\n",
        "  \n",
        "  @tf.function\n",
        "  def distributed_validation():\n",
        "    return strategy.experimental_run(validation_step, validation_iterator)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aRC06SKaGlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LEARNING RATE CALLBACK\n",
        "def get_symbolic_metric(metric_obj):  # needed by add_metric, see keras.metrics.Metric.__call__\n",
        "      result_t = metric_obj.result()\n",
        "      result_t._metric_obj = metric_obj\n",
        "      return result_t\n",
        "\n",
        "with strategy.scope():\n",
        "  generator.optimizer = generator_optimizer\n",
        "  discriminator.optimizer = discriminator_optimizer\n",
        "  generator.stop_training = False\n",
        "  discriminator.stop_training = False\n",
        "  \n",
        "  gen_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor=train_gen_loss.name, patience=10, verbose=True)\n",
        "  gen_lr_callback.set_model(generator)\n",
        "  disc_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor=train_disc_loss.name, patience=10, verbose=True)\n",
        "  disc_lr_callback.set_model(discriminator)\n",
        "  \n",
        "  gen_earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor=train_gen_loss.name, patience=30, restore_best_weights=True, verbose=True)\n",
        "  gen_earlystop_callback.set_model(generator)\n",
        "  disc_earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor=train_disc_loss.name, patience=30, restore_best_weights=True, verbose=True)\n",
        "  disc_earlystop_callback.set_model(discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvI6evPk1fZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TENSORBOARD\n",
        "logs_dir = '/content/musdb18/logs/'\n",
        "train_summary_writer = tf.summary.create_file_writer(logs_dir+'train')\n",
        "validation_summary_writer = tf.summary.create_file_writer(logs_dir+'validation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyu6itEcrZm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TENSORBOARD SUMMARY\n",
        "test_mixture, test_target = validation_iterator.get_next()\n",
        "test_mixture, test_target = tf.expand_dims(test_mixture[0], 0), tf.expand_dims(test_target[0], 0)\n",
        "validation_iterator.initialize()\n",
        "  \n",
        "def update_summary(epoch):\n",
        "  with train_summary_writer.as_default():\n",
        "    tf.summary.scalar('gen_loss', train_gen_loss.result(), step=epoch)\n",
        "    tf.summary.scalar('disc_loss', train_gen_loss.result(), step=epoch)\n",
        "    tf.summary.scalar('gen_lr', generator.optimizer.lr, step=epoch)\n",
        "    tf.summary.scalar('disc_lr', discriminator.optimizer.lr, step=epoch)\n",
        "  gen_output = tf.expand_dims(generator(test_mixture, training=False)[0], 0)\n",
        "  with validation_summary_writer.as_default():\n",
        "    tf.summary.scalar('gen_loss', validation_gen_loss.result(), step=epoch)\n",
        "    tf.summary.scalar('disc_loss', validation_disc_loss.result(), step=epoch)\n",
        "    \n",
        "    tf.summary.audio('audio_separation',\n",
        "                     tf.concat([test_mixture, gen_output, test_target], axis=0),\n",
        "                     44100,\n",
        "                     step=epoch,\n",
        "                     max_outputs=3,\n",
        "                     encoding=\"wav\"\n",
        "                    )\n",
        "  #!rsync -a --delete $logs_dir /content/gdrive/My\\ Drive/musdb18/logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pCieW11Tk_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  gen_lr_callback.on_train_begin()\n",
        "  disc_lr_callback.on_train_begin()\n",
        "  gen_earlystop_callback.on_train_begin()\n",
        "  disc_earlystop_callback.on_train_begin()\n",
        "  \n",
        "  for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    #train_iterator.initialize()\n",
        "    for _ in range(train_steps_per_epoch):\n",
        "      distributed_train()\n",
        "\n",
        "    #validation_iterator.initialize()\n",
        "    for _ in range(validation_steps_per_epoch):\n",
        "      distributed_validation()\n",
        "\n",
        "    # saving (checkpoint) the model every SAVE_FREQ epochs\n",
        "    if tf.equal((epoch+1) % SAVE_FREQ, 0):\n",
        "      ckpt_manager.save()\n",
        "      #!rsync -a --delete $checkpoint_dir /content/gdrive/My\\ Drive/musdb18/checkpoints\n",
        "      \n",
        "    if tf.equal((epoch+1) % LOG_FREQ, 0):\n",
        "      update_summary(epoch)\n",
        "    \n",
        "    logs = {\n",
        "        train_gen_loss.name: train_gen_loss.result(),\n",
        "        train_disc_loss.name: train_disc_loss.result(),\n",
        "        validation_gen_loss.name: validation_gen_loss.result(),\n",
        "        validation_disc_loss.name: validation_disc_loss.result()\n",
        "    }\n",
        "    gen_lr_callback.on_epoch_end(epoch, logs)\n",
        "    disc_lr_callback.on_epoch_end(epoch, logs)\n",
        "    gen_earlystop_callback.on_epoch_end(epoch, logs)\n",
        "    disc_earlystop_callback.on_epoch_end(epoch, logs)\n",
        "\n",
        "    template = (\"Epoch {} ({} sec)\\nGen Loss: {}, Disc Loss: {}, \"\n",
        "                \"Validation Gen Loss: {}, Validation Disc Loss: {}\")\n",
        "    tf.print(template.format(epoch+1, time.time()-start, \n",
        "                          logs[train_gen_loss.name], \n",
        "                          logs[train_disc_loss.name], \n",
        "                          logs[validation_gen_loss.name], \n",
        "                          logs[validation_disc_loss.name]))\n",
        "    if gen_earlystop_callback.model.stop_training and disc_earlystop_callback.model.stop_training:\n",
        "      break\n",
        "\n",
        "    train_gen_loss.reset_states()\n",
        "    train_disc_loss.reset_states()\n",
        "    validation_gen_loss.reset_states()\n",
        "    validation_disc_loss.reset_states()\n",
        "  gen_earlystop_callback.on_train_end()\n",
        "  disc_earlystop_callback.on_train_end()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ_lEnAt4KOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir $logs_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P7XyRMdjbPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EVALUATION FUNCS\n",
        "estimates_dir = \"/content/musdb18/estimates/\"\n",
        "evaluation_scores_dir = \"/content/musdb18/scores/\"\n",
        "\n",
        "def is_power2(num):\n",
        "  return num and not num & (num - 1)\n",
        "\n",
        "def preprocess_data(audio):\n",
        "  audio = tf.cast(audio, dtype=tf.float32)\n",
        "  audio_len = audio.shape[0]\n",
        "  if audio_len <= INPUT_SIZE:\n",
        "    # pad audio to nearest bigger power of 2, because upsample and downsample are not symmetric with length that are not power of 2\n",
        "    if not is_power2(audio_len):\n",
        "      new_width = 2**(int(np.log2(audio_len))+1)\n",
        "      paddings = new_width - audio_len\n",
        "      audio = tf.pad(audio, [(0, paddings), (0, 0)])\n",
        "    audio = tf.expand_dims(audio, 0)\n",
        "    return audio\n",
        "  paddings = INPUT_SIZE - (audio_len % INPUT_SIZE)\n",
        "  audio = tf.pad(audio, [(0, paddings), (0, 0)])\n",
        "  audio = tf.concat([tf.split(\n",
        "      audio,\n",
        "      [INPUT_SIZE] * (audio.shape[0] // INPUT_SIZE),\n",
        "      axis=0,\n",
        "  )], 0)\n",
        "  return audio\n",
        "  \n",
        "BATCH_SIZE = 64\n",
        "def postprocess_data(gen_output, original_width):\n",
        "  return tf.reshape(tf.concat(gen_output, 0), [-1, OUTPUT_CHANNELS])[:original_width].numpy()\n",
        "      \n",
        "def test_func(track):\n",
        "  data = preprocess_data(track.audio)\n",
        "  res = []\n",
        "  for i in range(0, data.shape[0], BATCH_SIZE):\n",
        "    res.append(generator(data[i:i+BATCH_SIZE], training=False))\n",
        "  data = postprocess_data(res, track.audio.shape[0])\n",
        "  data = {'vocals': data, 'accompaniment': track.audio - data}\n",
        "  \n",
        "  # Evaluate using museval, use EVALUATION ONLY to separate process\n",
        "  #scores = museval.eval_mus_track(\n",
        "  #    track, data, output_dir=evaluation_scores_dir\n",
        "  #)\n",
        "  \n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp69nY2XH4r6",
        "colab_type": "code",
        "outputId": "20d1066b-8df0-4b78-c98c-32f50d8be36d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        }
      },
      "source": [
        "# EVALUATE\n",
        "# mus.test(test_func)\n",
        "mus.run(test_func, subsets=\"test\", estimates_dir=estimates_dir)\n",
        "#!rsync -a --delete $estimates_dir /content/gdrive/My\\ Drive/musdb18/estimates\n",
        "#!rsync -a --delete $evaluation_scores_dir /content/gdrive/My\\ Drive/musdb18/scores"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [26:24<00:00, 26.19s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRDGf14YKT3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EVALUATION ONLY\n",
        "#!rm -rf $evaluation_scores_dir\n",
        "#museval.eval_mus_dir(\n",
        "#    dataset=mus,  # instance of musdb\n",
        "#    estimates_dir=estimates_dir,  # path to estimate folder\n",
        "#    output_dir=evaluation_scores_dir,  # set a folder to write eval json files\n",
        "#    subsets=\"test\",\n",
        "#    parallel=True\n",
        "#)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iScNsWIaPbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DISPLAY RESULTS\n",
        "import json\n",
        "from statistics import median\n",
        "import math\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "SDR, SIR, SAR, ISR = [], [], [], []\n",
        "for file in (Path(evaluation_scores_dir) / 'test').iterdir():\n",
        "  with open(file, 'r') as f:\n",
        "    data = json.loads(f.read())\n",
        "    frames = data['targets'][0]['frames']\n",
        "    SDR.append(median([frame['metrics']['SDR'] for frame in frames if not math.isnan(frame['metrics']['SDR'])]))\n",
        "    SIR.append(median([frame['metrics']['SIR'] for frame in frames if not math.isnan(frame['metrics']['SIR'])]))\n",
        "    SAR.append(median([frame['metrics']['SAR'] for frame in frames if not math.isnan(frame['metrics']['SAR'])]))\n",
        "    ISR.append(median([frame['metrics']['ISR'] for frame in frames if not math.isnan(frame['metrics']['ISR'])]))\n",
        "    \n",
        "fig = plt.figure()\n",
        "\n",
        "ax = plt.subplot(1, 4, 1) # (rows, columns, panel number)\n",
        "ax.set_title('SDR')\n",
        "plt.boxplot(SDR, vert=False, notch=True, showfliers=False)\n",
        "\n",
        "ax = plt.subplot(1, 4, 2)\n",
        "ax.set_title('SIR')\n",
        "plt.boxplot(SIR, vert=False, notch=True, showfliers=False)\n",
        "\n",
        "ax = plt.subplot(1, 4, 3)\n",
        "ax.set_title('SAR')\n",
        "plt.boxplot(SAR, vert=False, notch=True, showfliers=False)\n",
        "\n",
        "ax = plt.subplot(1, 4, 4)\n",
        "ax.set_title('ISR')\n",
        "plt.boxplot(ISR, vert=False, notch=True, showfliers=False)\n",
        "fig.savefig(Path(evaluation_scores_dir) / 'result.png')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}